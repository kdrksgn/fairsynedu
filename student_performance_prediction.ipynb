{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Academic Performance Prediction\n",
    "\n",
    "This notebook implements the methodology described in the paper 'Beyond Performance: Explaining and Ensuring Fairness in Student Academic Performance Prediction with Machine Learning' (Appl. Sci. 2020, 10). It uses the UCI Student Performance dataset to predict student performance (G3) using Logistic Regression, Random Forest, and XGBoost, with SMOTE for class imbalance, fairness analysis via AIF360, and explainability via SHAP and LIME.\n",
    "\n",
    "## Dependencies\n",
    "- Python 3.10\n",
    "- pandas (1.5.3)\n",
    "- numpy (1.25.2)\n",
    "- scikit-learn (1.2.2)\n",
    "- xgboost (1.5.0)\n",
    "- imbalanced-learn (0.10.1)\n",
    "- aif360 (0.5.0)\n",
    "- shap (0.41.0)\n",
    "- lime (0.2.0.1)\n",
    "\n",
    "## Dataset\n",
    "- UCI Student Performance Dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student-por.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install pandas==1.5.3 numpy==1.25.2 scikit-learn==1.2.2 xgboost==1.5.0 imbalanced-learn==0.10.1 aif360==0.5.0 shap==0.41.0 lime==0.2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.metrics import ClassificationMetric\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the UCI Student Performance dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student-por.csv\"\n",
    "data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Preprocess the data\n",
    "# Convert the target variable G3 to binary: pass (>=10) or fail (<10)\n",
    "data['G3'] = data['G3'].apply(lambda x: 1 if x >= 10 else 0)\n",
    "\n",
    "# Define features and target\n",
    "features = ['G1', 'G2', 'absences', 'failures', 'Medu', 'Fedu', 'sex', 'school', 'Pstatus', 'famsize']\n",
    "X = data[features]\n",
    "y = data['G3']\n",
    "\n",
    "# Encode categorical variables\n",
    "X = pd.get_dummies(X, columns=['sex', 'school', 'Pstatus', 'famsize'], drop_first=True)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training: Logistic Regression, Random Forest, XGBoost\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning for Random Forest and XGBoost\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None]\n",
    "}\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='f1')\n",
    "grid_xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=5, scoring='f1')\n",
    "\n",
    "# Train models\n",
    "models['Random Forest'] = grid_rf.fit(X_train_smote, y_train_smote).best_estimator_\n",
    "models['XGBoost'] = grid_xgb.fit(X_train_smote, y_train_smote).best_estimator_\n",
    "models['Logistic Regression'].fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Print model performance\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name} - Accuracy: {metrics['Accuracy']:.3f}, F1 Score: {metrics['F1 Score']:.3f}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.to_csv('model_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness Analysis with AIF360\n",
    "# Define protected attributes (e.g., sex_M)\n",
    "privileged_groups = [{'sex_M': 1}]\n",
    "unprivileged_groups = [{'sex_M': 0}]\n",
    "dataset_orig = BinaryLabelDataset(df=pd.concat([X_test, y_test], axis=1), \n",
    "                                 label_names=['G3'], \n",
    "                                 protected_attribute_names=['sex_M'])\n",
    "\n",
    "# Apply Reweighing for fairness\n",
    "rw = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "dataset_transf = rw.fit_transform(dataset_orig)\n",
    "\n",
    "# Evaluate fairness metrics\n",
    "metric = ClassificationMetric(dataset_orig, dataset_transf, \n",
    "                             unprivileged_groups=unprivileged_groups, \n",
    "                             privileged_groups=privileged_groups)\n",
    "print(f\"Demographic Parity Difference: {metric.differential_fairness_bias_metrics()['DP']:.3f}\")\n",
    "print(f\"Equalized Odds Difference: {metric.equal_opportunity_difference():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainability with SHAP\n",
    "explainer = shap.LinearExplainer(models['Logistic Regression'], X_train_smote)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainability with LIME\n",
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train_smote.values, \n",
    "    feature_names=X_train_smote.columns, \n",
    "    class_names=['Fail', 'Pass'], \n",
    "    mode='classification'\n",
    ")\n",
    "lime_exp = lime_explainer.explain_instance(X_test.iloc[0].values, models['Logistic Regression'].predict_proba)\n",
    "lime_exp.show_in_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}